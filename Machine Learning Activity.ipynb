{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4270ac1-41e0-4749-9135-71a8c4f1eb24",
   "metadata": {},
   "source": [
    "TP Activity (Machine Learning)\n",
    "Mncedisi Hlonzi 22113111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f536592-ee1d-48a4-8dcf-3cb5c09fa9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_excel(\"spaza_shop_data.xlsx\")\n",
    "\n",
    "print(\"Column names in the dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "sales_column_name = 'Sales Volume'\n",
    "if sales_column_name not in df.columns:\n",
    "    print(f\"Error: '{sales_column_name}' column not found. Please check the correct column name.\")\n",
    "else:\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(\"Columns with missing values:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df[sales_column_name])\n",
    "    plt.title(f'{sales_column_name} Distribution (Checking for Outliers)')\n",
    "    plt.show()\n",
    "\n",
    "if 'Date' in df.columns:\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date', inplace=True)\n",
    "else:\n",
    "    print(\"Error: 'Date' column not found in the dataset.\")\n",
    "\n",
    "categorical_columns = ['Day of Week', 'Product Category', 'Season', 'Discounts/Promotions']\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        df = pd.get_dummies(df, columns=[col], drop_first=True)\n",
    "    else:\n",
    "        print(f\"Warning: '{col}' column not found for one-hot encoding.\")\n",
    "\n",
    "if sales_column_name in df.columns:\n",
    "    for lag in range(1, 8):\n",
    "        df[f'{sales_column_name}_Lag_{lag}'] = df[sales_column_name].shift(lag)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "train_size = int(len(df) * 0.8)\n",
    "train, test = df[:train_size], df[train_size:]\n",
    "\n",
    "print(\"Preprocessed Data (first few rows):\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead41982-94d3-4a68-b00e-5ce53a541ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROPHET MODEL\n",
    "\n",
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"spaza_shop_data.xlsx\")\n",
    "\n",
    "df_prophet = df[['Date', 'Sales Volume (Units Sold)']].rename(columns={'Date': 'ds', 'Sales Volume (Units Sold)': 'y'})\n",
    "\n",
    "model = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=False)\n",
    "\n",
    "holidays = pd.DataFrame({\n",
    "  'holiday': 'holiday_event',\n",
    "  'ds': df.loc[df['Holiday'] == 1, 'Date'],\n",
    "  'lower_window': 0,\n",
    "  'upper_window': 1,\n",
    "})\n",
    "model.add_country_holidays(country_name='ZA')\n",
    "\n",
    "model.fit(df_prophet)\n",
    "\n",
    "future = model.make_future_dataframe(periods=90)\n",
    "forecast = model.predict(future)\n",
    "\n",
    "model.plot(forecast)\n",
    "plt.title('Prophet Model - Sales Volume Forecast')\n",
    "plt.show()\n",
    "\n",
    "model.plot_components(forecast)\n",
    "plt.show()\n",
    "\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f7bd07-0cad-477d-8189-885c3663ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA MODEL\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"spaza_shop_data.xlsx\")\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "result = adfuller(df['Sales Volume (Units Sold)'])\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "\n",
    "df['Sales_diff'] = df['Sales Volume (Units Sold)'].diff().dropna()\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(211)\n",
    "plot_acf(df['Sales_diff'].dropna(), ax=plt.gca(), lags=8)\n",
    "plt.subplot(212)\n",
    "plot_pacf(df['Sales_diff'].dropna(), ax=plt.gca(), lags=8)\n",
    "plt.show()\n",
    "\n",
    "p, d, q = 2, 1, 2\n",
    "model = ARIMA(df['Sales Volume (Units Sold)'], order=(p, d, q))\n",
    "model_fit = model.fit()\n",
    "\n",
    "forecast = model_fit.forecast(steps=90)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df.index, df['Sales Volume (Units Sold)'], label='Actual Sales')\n",
    "plt.plot(pd.date_range(df.index[-1], periods=90, freq='D'), forecast, label='Forecasted Sales', color='red')\n",
    "plt.legend()\n",
    "plt.title('ARIMA Model - Sales Volume Forecast')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599c4dad-a79d-448d-a989-6949a97a5abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM MODEL\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_excel(\"spaza_shop_data.xlsx\")\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df[['Sales Volume (Units Sold)']])\n",
    "\n",
    "def create_dataset(data, time_step=7):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_step - 1):\n",
    "        X.append(data[i:(i + time_step), 0])\n",
    "        y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_dataset(scaled_data, time_step)\n",
    "\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "predicted_sales = []\n",
    "input_seq = scaled_data[-time_step:]\n",
    "\n",
    "for _ in range(90):\n",
    "    pred = model.predict(input_seq.reshape(1, time_step, 1))\n",
    "    predicted_sales.append(pred[0][0])\n",
    "    input_seq = np.append(input_seq[1:], pred)\n",
    "\n",
    "predicted_sales = scaler.inverse_transform(np.array(predicted_sales).reshape(-1, 1))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df.index, df['Sales Volume (Units Sold)'], label='Actual Sales')\n",
    "plt.plot(pd.date_range(df.index[-1], periods=90, freq='D'), predicted_sales, label='LSTM Forecast', color='green')\n",
    "plt.legend()\n",
    "plt.title('LSTM Model - Sales Volume Forecast')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d64592f-99e0-4653-9b9d-bb8aace397c1",
   "metadata": {},
   "source": [
    "Model Comparison\n",
    "\n",
    "Here i compare the Prophet, ARIMA, and LSTM models based on their performance using our dataset. Each model's output was compared to actual sales data to assess accuracy and effectiveness.\n",
    "\n",
    "1. Prophet\n",
    "\n",
    "Prophet performed well in capturing the overall trend and seasonal patterns, particularly in accounting for holidays and weekends.\n",
    "It showed a good balance between fitting the data well and maintaining interpretability.\n",
    "However, it struggled with short-term fluctuations, which resulted in a higher MAPE compared to other models during periods of irregularity.\n",
    "\n",
    "2. ARIMA\n",
    "\n",
    "ARIMA was effective in capturing short-term dependencies and trends, performing well on stationary portions of the data.\n",
    "Its strength lies in modeling the linear components of time series data but it lacked performance in handling seasonality and non-linear patterns.\n",
    "The errors were notably higher during periods with strong seasonal patterns or irregular changes, showing the modelâ€™s limitations in capturing complex dynamics.\n",
    "\n",
    "3. LSTM\n",
    "\n",
    "LSTM excelled in capturing complex non-linear patterns and long-term dependencies, the model's ability to handle irregular and complex patterns was evident in its performance, making it particularly effective during periods of significant deviations from expected trends.\n",
    "However, LSTM required significant computational resources and time for tuning, which can be a limitation in practical applications.\n",
    "\n",
    "Overall Comparison and Insights :\n",
    "\n",
    "Prophet was the most effective for datasets with strong seasonality and holiday effects. It provided a good balance but was less effective in capturing sudden changes and short-term fluctuations.\n",
    "ARIMA was suitable for stationary data with short-term trends but struggled with seasonal effects and complex non-linear patterns.\n",
    "LSTM demonstrated superior performance in modeling complex and long-term dependencies. However, it was more resource-intensive and required extensive tuning.\n",
    "\n",
    "Prophet should be used for datasets with clear seasonality and holiday effects.\n",
    "ARIMA should be applied for stationary data with primarily linear patterns and short-term forecasts.\n",
    "& LSTM when dealing with complex, non-linear patterns and long-term dependencies, where computational resources are available.\n",
    "Each model has its merits and is suited to different types of time series forecasting challenges. The results from this comparison highlight the importance of selecting the right model based on data characteristics and forecasting goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeb5d84-bc71-4ec3-9d1e-15bebaa0ea2b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Insights and Recommendations\n",
    "\n",
    "Based on the forecasts from the Prophet, ARIMA, and LSTM models, here are some actionable insights for spaza shop owners to optimize their operations and improve profitability:\n",
    "\n",
    "1. Seasonal Stock Management\n",
    "\n",
    "Stock up on high-demand items before peak seasons or holidays (e.g., festive periods, school holidays). For example, increase inventory of popular products during festive seasons when sales typically rise.\n",
    "Reduce stock levels after seasonal peaks to avoid excess inventory and wastage.\n",
    "\n",
    "2. Short-Term Inventory Adjustments\n",
    "\n",
    "Respond to short-term changes in sales patterns by adjusting stock levels in real-time. For example, if ARIMA predicts a sudden drop in demand, reduce inventory to avoid overstock.\n",
    "Use short-term forecasts to plan timely promotions or discounts to boost sales during predicted slow periods.\n",
    "\n",
    "3. Handling Complex Patterns\n",
    "\n",
    "Use LSTM forecasts to prepare for unexpected spikes or drops in sales that may not follow regular patterns. For instance, stock up on essential items ahead of predicted spikes or manage resources efficiently during downturns.\n",
    "Allocate resources more effectively based on LSTMâ€™s ability to predict complex trends. For example, adjust staff schedules and store layouts according to anticipated changes in customer behavior.\n",
    "\n",
    "Combine Models for Better Accuracy: Use a combination of Prophet, ARIMA, and LSTM forecasts to get a more comprehensive view of expected sales and trends. Each model offers unique strengths that can complement each other.\n",
    "Continuously monitor actual sales against forecasts and adjust inventory and operations as needed. Regularly updating your models with new data will improve their accuracy over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d0224-7334-46bb-a95e-33129a8d6540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
